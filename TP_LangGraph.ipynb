{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# TP -- Introduction to LangGraph\n\n## What is LangGraph?\n\n[LangGraph](https://langchain-ai.github.io/langgraph/) is a Python framework for building **stateful, multi-step workflows** (often called *agentic* workflows). It models your application as a **directed graph** where:\n\n- **State** is a shared data structure that flows through the graph.\n- **Nodes** are Python functions that read from the state and return updates.\n- **Edges** define the order in which nodes execute, including conditional branching.\n\nThis is particularly useful for AI pipelines, but the concepts apply to any multi-step process.\n\n## What we're building\n\nA simplified **email threat classifier** inspired by a real-world spam detection system. The pipeline:\n\n1. Checks email URLs against a blocklist\n2. Analyzes the email content for phishing keywords\n3. Classifies the email as `safe`, `suspicious`, or `dangerous`\n4. Generates a response message\n\nYou'll work in the `email_classifier/` package. Each part has `TODO` sections to fill in. Run the verification cells in this notebook to check your work.\n\n**No API keys are required** -- everything uses mock data."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup\n",
    "\n",
    "Run the cell below to install dependencies and verify the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q langgraph langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick sanity check\n",
    "import langgraph\n",
    "print(f\"LangGraph version: {langgraph.__version__}\")\n",
    "print(\"Setup OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Part 1 -- State Schema\n\n### Concept\n\nIn LangGraph, the **state** is the single source of truth that every node can read and write to. It is defined as a Pydantic `BaseModel`. Each field in the model represents a piece of data that flows through the graph.\n\nWhen a node returns `{\"threat_level\": \"dangerous\"}`, LangGraph merges that into the current state, updating only the `threat_level` field and leaving everything else untouched.\n\n### TODO\n\nOpen **`email_classifier/state.py`**. Most fields are already declared. Fill in the **three TODO fields**:\n- `email_id` — a `str` with default `\"\"`\n- `has_attachments` — a `bool` with default `False`\n- `content_analysis` — an `Optional[dict]` with default `None`\n\nUse the existing fields as examples. Then run the verification cell below."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from email_classifier.checks import check_part1\ncheck_part1()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Part 2 -- Function Nodes\n\n### Concept\n\nA **node** in LangGraph is just a regular Python function with this signature:\n\n```python\ndef my_node(state: dict) -> dict:\n    # read from state\n    value = state[\"some_key\"]\n    # do some work\n    result = process(value)\n    # return ONLY the keys you want to update\n    return {\"output_key\": result}\n```\n\nKey rules:\n- The function receives the **full current state** as a dict.\n- It returns a dict with **only the keys it wants to update** -- not the entire state.\n- LangGraph merges the returned dict into the state automatically.\n\n### TODO\n\nOpen **`email_classifier/nodes.py`**. Nodes 1 (`check_urls`) and 2 (`analyze_content`) are already implemented -- read them to understand the pattern. Then implement:\n- `classify_email` -- decide the threat level based on URL and content results\n- `generate_response` -- return the appropriate message string\n\nThen run the verification cells below."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from email_classifier.checks import check_classify_email\ncheck_classify_email()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from email_classifier.checks import check_generate_response\ncheck_generate_response()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Part 3 -- Graph Declaration\n\n### Concept\n\nNow that we have a state schema and node functions, we connect them into a **graph**.\n\n```\ncheck_urls --> analyze_content --?--> classify_email --> generate_response --> END\n                                 |                             ^\n                                 +-- (malicious URLs) --------+\n```\n\nThe `?` represents a **conditional edge**: after `analyze_content`, if the URL check already found something malicious, we skip `classify_email` and jump straight to `generate_response` (since the verdict is already `dangerous`).\n\nKey API:\n```python\nfrom langgraph.graph import StateGraph, END\n\nworkflow = StateGraph(MyState)\nworkflow.add_node(\"name\", my_function)\nworkflow.set_entry_point(\"first_node\")\nworkflow.add_edge(\"a\", \"b\")              # a always goes to b\nworkflow.add_conditional_edges(\n    \"source_node\",\n    routing_function,                     # returns a string\n    {\"option1\": \"node1\", \"option2\": \"node2\"}\n)\ngraph = workflow.compile()\n```\n\n### TODO\n\nOpen **`email_classifier/graph.py`**. Most of the graph is already wired up. Fill in the two TODOs:\n1. Add the `\"classify_email\"` node (follow the pattern of the other `add_node` calls)\n2. Add a normal edge from `\"classify_email\"` to `\"generate_response\"`\n\nThen run the verification cells below."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from email_classifier.checks import check_graph_build\ngraph = check_graph_build()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from email_classifier.checks import check_graph_results\ncheck_graph_results(graph)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Bonus: Visualize the graph =====\n",
    "# This prints a Mermaid diagram of your graph.\n",
    "# You can paste it into https://mermaid.live to see it rendered.\n",
    "\n",
    "print(graph.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Part 4 -- Human-in-the-Loop\n\n### Concept\n\nIn real-world systems, some decisions should not be fully automated. LangGraph supports **human-in-the-loop** (HITL) patterns where the graph can **pause** execution, let a human inspect and modify the state, and then **resume**.\n\nThis is done with:\n- A **checkpointer** (e.g. `MemorySaver`) that saves the graph state between runs.\n- **`interrupt_before`** (or `interrupt_after`): a list of node names where the graph should pause.\n- **`graph.invoke()`** to start or resume execution (with a `thread_id` config).\n- After the interrupt, you can **update the state** and call `invoke` again with `None` to resume.\n\n```python\nfrom langgraph.checkpoint.memory import MemorySaver\n\ncheckpointer = MemorySaver()\ngraph = workflow.compile(\n    checkpointer=checkpointer,\n    interrupt_before=[\"human_review\"]   # pause BEFORE this node\n)\n\n# Run until interrupt\nconfig = {\"configurable\": {\"thread_id\": \"my-thread\"}}\nstate = graph.invoke(input_data, config)\n# --> graph pauses before human_review\n\n# Human inspects state, optionally updates it\ngraph.update_state(config, {\"threat_level\": \"safe\"})\n\n# Resume\nfinal_state = graph.invoke(None, config)\n```\n\n### TODO\n\nOpen **`email_classifier/hitl.py`** and implement:\n1. `route_after_classify` -- routing function for the HITL graph\n2. `build_hitl_graph` -- graph builder with interrupt support\n\nThen run the verification cells below."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from email_classifier.checks import check_hitl_build\nhitl_graph = check_hitl_build()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from email_classifier.checks import check_hitl_safe\ncheck_hitl_safe(hitl_graph)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from email_classifier.checks import check_hitl_interrupt\nconfig = check_hitl_interrupt(hitl_graph)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# The graph is paused. You decide what happens next.\ndecision = input(\"What is your verdict? (safe / suspicious / dangerous): \").strip().lower()\nwhile decision not in (\"safe\", \"suspicious\", \"dangerous\"):\n    decision = input(\"Please enter one of: safe, suspicious, dangerous: \").strip().lower()\n\nhitl_graph.update_state(config, {\"threat_level\": decision})\nfinal_state = hitl_graph.invoke(None, config)\n\nprint(f\"\\nYou chose: {decision}\")\nprint(f\"Final response: {final_state['response']}\")\nprint(\"\\n=== Human-in-the-Loop PASSED ===\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Bonus: Visualize the HITL graph =====\n",
    "print(hitl_graph.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Summary\n\nThat's it! Here's what we covered:\n\n| Concept | What you saw |\n|---------|-------------|\n| **State Schema** | Define a Pydantic `BaseModel` that holds all data flowing through the graph |\n| **Function Nodes** | Write functions that read state and return partial updates |\n| **Graph Declaration** | Connect nodes with edges (linear and conditional) and compile |\n| **Human-in-the-Loop** | Use `interrupt_before` + checkpointer to pause, inspect, and resume |\n\n### Going further\n\n- **Subgraphs**: nest one graph inside another\n- **Reducers**: use `Annotated[list, operator.add]` to accumulate values instead of overwriting\n- **Persistence**: replace `MemorySaver` with a database-backed checkpointer for production\n- **Streaming**: use `graph.stream()` to see node-by-node output in real time\n- **LangGraph docs**: https://langchain-ai.github.io/langgraph/"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}