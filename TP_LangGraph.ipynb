{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP -- Introduction to LangGraph\n",
    "\n",
    "## What is LangGraph?\n",
    "\n",
    "[LangGraph](https://langchain-ai.github.io/langgraph/) is a Python framework for building **stateful, multi-step workflows** (often called *agentic* workflows). It models your application as a **directed graph** where:\n",
    "\n",
    "- **State** is a shared data structure that flows through the graph.\n",
    "- **Nodes** are Python functions that read from the state and return updates.\n",
    "- **Edges** define the order in which nodes execute, including conditional branching.\n",
    "\n",
    "This is particularly useful for AI pipelines, but the concepts apply to any multi-step process.\n",
    "\n",
    "## What we're building\n",
    "\n",
    "A simplified **email threat classifier** inspired by a real-world spam detection system. The pipeline:\n",
    "\n",
    "1. Checks email URLs against a blocklist\n",
    "2. Analyzes the email content for phishing keywords\n",
    "3. Classifies the email as `safe`, `suspicious`, or `dangerous`\n",
    "4. Generates a response message\n",
    "\n",
    "You'll work in the `email_classifier/` package. Each part has `TODO` sections to fill in. Run the verification cells in this notebook to check your work.\n",
    "\n",
    "**No API keys are required** -- everything uses mock data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup\n",
    "\n",
    "Run the cell below to install dependencies and verify the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q langgraph langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick sanity check\n",
    "import langgraph\n",
    "from importlib.metadata import version\n",
    "\n",
    "print(f\"LangGraph version: {version('langgraph')}\")\n",
    "print(\"Setup OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1 -- State Schema\n",
    "\n",
    "### Concept\n",
    "\n",
    "In LangGraph, the **state** is the single source of truth that every node can read and write to. It is defined as a Pydantic `BaseModel`. Each field in the model represents a piece of data that flows through the graph.\n",
    "\n",
    "When a node returns `{\"threat_level\": \"dangerous\"}`, LangGraph merges that into the current state, updating only the `threat_level` field and leaving everything else untouched.\n",
    "\n",
    "### TODO\n",
    "\n",
    "Open **`email_classifier/state.py`**. Most fields are already declared. Fill in the **three TODO fields**:\n",
    "- `email_id` — a `str` with default `\"\"`\n",
    "- `has_attachments` — a `bool` with default `False`\n",
    "- `content_analysis` — an `Optional[dict]` with default `None`\n",
    "\n",
    "Use the existing fields as examples. Then run the verification cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from email_classifier.checks import check_part1\n",
    "check_part1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Part 2 -- Function Nodes\n\n### Concept\n\nA **node** in LangGraph is just a regular Python function with this signature:\n\n```python\ndef my_node(state: EmailState) -> dict:\n    # read from state using dot notation\n    value = state.some_key\n    # do some work\n    result = process(value)\n    # return ONLY the keys you want to update\n    return {\"output_key\": result}\n```\n\nKey rules:\n- The function receives the **full current state** as a Pydantic model instance.\n- Access fields with **dot notation** (e.g. `state.urls`, not `state[\"urls\"]`).\n- It returns a dict with **only the keys it wants to update** -- not the entire state.\n- LangGraph merges the returned dict into the state automatically.\n\n### TODO\n\nOpen **`email_classifier/nodes.py`**. Node 1 (`check_urls`) is already implemented -- read it to understand the pattern. Then implement:\n- `analyze_content` -- analyze the email content and set the threat level\n- `generate_response` -- return the appropriate message string\n\nThen run the verification cells below."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from email_classifier.checks import check_analyze_content\ncheck_analyze_content()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from email_classifier.checks import check_generate_response\n",
    "check_generate_response()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Part 3 -- Graph Declaration\n\n### Concept\n\nNow that we have a state schema and node functions, we connect them into a **graph**.\n\n```\ncheck_urls --?--> analyze_content --> generate_response --> END\n              |                              ^\n              +-- (malicious URLs) ----------+\n```\n\nThe `?` represents a **conditional edge**: after `check_urls`, if malicious URLs were found, we skip straight to `generate_response` (since the verdict is already `dangerous`). Otherwise we continue through `analyze_content`.\n\nKey API:\n```python\nfrom langgraph.graph import StateGraph, START, END\n\nworkflow = StateGraph(MyState)\nworkflow.add_node(\"name\", my_function)\nworkflow.add_edge(START, \"first_node\")   # set the entry point\nworkflow.add_edge(\"a\", \"b\")              # a always goes to b\nworkflow.add_conditional_edges(\n    \"source_node\",\n    routing_function,                     # returns a string\n    {\"option1\": \"node1\", \"option2\": \"node2\"}\n)\ngraph = workflow.compile()\n```\n\n### TODO\n\nOpen **`email_classifier/graph.py`**. Most of the graph is already wired up. Fill in the two TODOs:\n1. Add the `\"analyze_content\"` node (follow the pattern of the other `add_node` calls)\n2. Add a normal edge from `\"analyze_content\"` to `\"generate_response\"`\n\nThen run the verification cells below."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from email_classifier.checks import check_graph_build\n",
    "graph = check_graph_build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from email_classifier.checks import check_graph_results\n",
    "check_graph_results(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Bonus: Visualize the graph =====\n",
    "# This prints a Mermaid diagram of your graph.\n",
    "# You can paste it into https://mermaid.live to see it rendered.\n",
    "\n",
    "print(graph.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Part 4 -- Human-in-the-Loop\n\n### Concept\n\nIn real-world systems, some decisions should not be fully automated. LangGraph supports **human-in-the-loop** (HITL) patterns where the graph can **pause** execution, let a human inspect and modify the state, and then **resume**.\n\nThis is done with:\n- A **checkpointer** (e.g. `InMemorySaver`) that saves the graph state between runs.\n- **`interrupt_before`** (or `interrupt_after`): a list of node names where the graph should pause.\n- **`graph.invoke()`** to start or resume execution (with a `thread_id` config).\n- After the interrupt, you can **update the state** and call `invoke` again with `None` to resume.\n\n```python\nfrom langgraph.checkpoint.memory import InMemorySaver\n\ncheckpointer = InMemorySaver()\ngraph = workflow.compile(\n    checkpointer=checkpointer,\n    interrupt_before=[\"human_review\"]   # pause BEFORE this node\n)\n\n# Run until interrupt\nconfig = {\"configurable\": {\"thread_id\": \"my-thread\"}}\nstate = graph.invoke(input_data, config)\n# --> graph pauses before human_review\n\n# Human inspects state, optionally updates it\ngraph.update_state(config, {\"threat_level\": \"safe\"})\n\n# Resume\nfinal_state = graph.invoke(None, config)\n```\n\n### TODO\n\nOpen **`email_classifier/hitl.py`** and implement:\n1. `route_after_analysis` -- routing function that sends suspicious emails to human review\n2. `build_hitl_graph` -- graph builder with interrupt support\n\nThen run the verification cells below."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from email_classifier.checks import check_hitl_build\n",
    "hitl_graph = check_hitl_build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from email_classifier.checks import check_hitl_safe\n",
    "check_hitl_safe(hitl_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from email_classifier.checks import check_hitl_interrupt\n",
    "config = check_hitl_interrupt(hitl_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The graph is paused. You decide what happens next.\n",
    "decision = input(\"What is your verdict? (safe / suspicious / dangerous): \").strip().lower()\n",
    "while decision not in (\"safe\", \"suspicious\", \"dangerous\"):\n",
    "    decision = input(\"Please enter one of: safe, suspicious, dangerous: \").strip().lower()\n",
    "\n",
    "hitl_graph.update_state(config, {\"threat_level\": decision})\n",
    "final_state = hitl_graph.invoke(None, config)\n",
    "\n",
    "print(f\"\\nYou chose: {decision}\")\n",
    "print(f\"Final response: {final_state['response']}\")\n",
    "print(\"\\n=== Human-in-the-Loop PASSED ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Bonus: Visualize the HITL graph =====\n",
    "print(hitl_graph.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Summary\n\nThat's it! Here's what we covered:\n\n| Concept | What you saw |\n|---------|-------------|\n| **State Schema** | Define a Pydantic `BaseModel` that holds all data flowing through the graph |\n| **Function Nodes** | Write functions that read state and return partial updates |\n| **Graph Declaration** | Connect nodes with edges (linear and conditional) and compile |\n| **Human-in-the-Loop** | Use `interrupt_before` + checkpointer to pause, inspect, and resume |\n\n### Going further\n\n- **Subgraphs**: nest one graph inside another\n- **Reducers**: use `Annotated[list, operator.add]` to accumulate values instead of overwriting\n- **Persistence**: replace `InMemorySaver` with a database-backed checkpointer for production\n- **Streaming**: use `graph.stream()` to see node-by-node output in real time\n- **LangGraph docs**: https://langchain-ai.github.io/langgraph/"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}